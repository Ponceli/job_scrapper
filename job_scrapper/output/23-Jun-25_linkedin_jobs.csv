date_time,search_keyword,search_count,job_id,job_title,company,location,remote,update_time,applicants,job_pay,job_time,job_position,company_size,company_industry,job_details,job_url
23Jun2025-16:05:11,Data Scientist,0,4253310620,Senior Data Scientist,SoTalent,Estados Unidos,false,hace 3 horas,100,,,,,,"Acerca del empleo Job Title: Senior Data Scientist Location: Remote Type: Full time  We’re looking for a Senior Data Scientist with a strong background in AI, machine learning, and advanced analytics to join a forward-thinking, collaborative team. In this role, you’ll lead high-impact data initiatives, design intelligent solutions, and work cross-functionally to solve real-world business problems with data.  What You’ll Do: Build and deploy machine learning models and data pipelines Apply advanced analytical techniques to drive business decisions Collaborate with engineering, product, and analytics teams Evaluate new technologies and tools in AI/ML Turn complex data into clear, actionable insights  What We’re Looking For: 6+ years of hands-on data science experience Proficient in Python, R, SQL, and modern visualization tools (e.g., Power BI, Tableau) Strong understanding of cloud-based platforms and data systems Experience delivering end-to-end ML solutions in production Excellent communication and collaboration skills  Nice to Have: Experience with GenAI or emerging AI technologies Familiarity with agile methodologies and experimentation frameworks  What You’ll Get: Competitive benefits including healthcare, retirement plans, and generous PTO Tuition reimbursement and professional development support Paid volunteer time and inclusive employee resource groups A supportive, flexible work culture focused on growth",https://www.linkedin.com/jobs/view/4253310620/?eBP=NOT_ELIGIBLE_FOR_CHARGING&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=YUZyGukQ6fhD8dCRI7Ub1g%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:05:30,Data Scientist,0,4255315046,Sr. Data Analyst,Gravity IT Resources,Estados Unidos,false,hace 2 horas,100,,,,,,"Acerca del empleo Job Title:  Sr Data Analyst  Location: Remote Job-Type: 12-month contract  Our client is a $20B, Fortune 200 company in the automotive retailing, distribution and services industry. They are currently ranked in the Top 20 companies to work for in the US by Fortune Magazine, Top 20 best companies for diversity and have an amazing work culture and impressive long-term growth prospects.  Job Summary:  The Sr. Data Analyst will be responsible developing an understanding of the relationship of the data that supports business processes and applications. The analyst will gain insights into the data and the movement of the data from data entry to final data destinations in the back-end files and reporting systems. Candidates must possess the technical capabilities to extract, retrieve and analyze data on their own. Be able to dive in and research new and complex data sources to understand how the data is moving in the system and how the data is stored to identify any anomalies that may exist. The analyst should possess strong interpersonal communication skills to be able to bridge the gap between business and technical users to relay both business and technical concepts as it relates to data. The analyst will be required to document findings and ensure that mappings and lineage are well documented and stored into knowledge storage repositories. This assignment is for a project that will interact with business and IT to understand business processes and the related data. Must be able to be on a hybrid schedule (Deerfield Beach office) with flexibility to be in the office more, as required.   Job Requirements:   o 5+ years of experience as a Data Analyst   o Senior level proficiency with SQL o Ability to independently complete data lineage projects and source to target mapping   o BA or BS Degree in Data Analytics, Computer Science or a related field   o Excellent communication skills and ability to effectively communicate with technical and business teams   o Executive / business presence  o Ability to develop trusted partnerships with stakeholders and other employees.",https://www.linkedin.com/jobs/view/4255315046/?eBP=NOT_ELIGIBLE_FOR_CHARGING&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=QTGMsYfSAO3sLX%2F5iOMAtw%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:05:44,Data Scientist,0,4255195040,Senior Data Scientist,Empiric,Estados Unidos,false,hace 5 horas,100,,,,,,"Acerca del empleo Senior Data Scientist / Machine Learning Engineer  Location: Remote  Contract: 6 months initial  Rate: $75-$90 per hour   Impact of Your Role As a Senior Data Scientist / Machine Learning Engineer, you will: Develop innovative solutions utilizing Large Language Models (LLMs) on customer data, including Retrieval-Augmented Generation (RAG) and agentic architectures, to enhance enterprise knowledge repositories. Implement natural language querying for structured data and facilitate content generation. Expand customer data science capabilities by applying best practices in MLOps to ensure successful deployment across diverse domains. Provide strategic guidance to data teams on architecture, tools, and best practices in data science. Offer technical mentorship to the broader Machine Learning Subject Matter Expert community. Required Experience: Proficiency in advanced natural language processing techniques, including vector databases, LLM fine-tuning, and deployment using tools such as HuggingFace, Langchain, and OpenAI. 5 to 6+ years of hands-on experience in production data science, utilizing tools such as pandas, scikit-learn, gensim, nltk, and TensorFlow/PyTorch. Proven track record of building production-grade machine learning solutions on cloud platforms like AWS, Azure, or GCP. Strong ability to communicate complex technical concepts effectively to both technical and non-technical audiences. Experience with Apache Spark™ for processing large-scale distributed datasets. Familiarity with the Databricks platform. At least 2 years of customer-facing experience in a pre-sales or similarly technical role.",https://www.linkedin.com/jobs/view/4255195040/?eBP=NOT_ELIGIBLE_FOR_CHARGING&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=oh%2BCxI132HOsbWKK1vYr8g%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:06:00,Data Scientist,0,4255246733,Junior Data Analyst,Insight Global,Estados Unidos,false,hace 51 minutos,100,,,,,,"Acerca del empleo Title: Data Analyst (Junior to Mid-Level Experience) Location: 100% Remote Duration: Contract (3 months + extensions) Compensation: $30/hr to $35/hr. Exact compensation may vary based on several factors, including skills, experience, and education.  Healthcare benefit packages for this role will start on the 1st day of employment and include medical, dental, and vision insurance, financial protection benefits, as well as HSA, FSA, and DCFSA account options. 401k retirement account access is offered starting on the 90th day with employer matching after one year of service. Employees in this role are also entitled to paid sick leave and/or other paid time off as provided by applicable law.  Required Skills & Experience 2-3 years’ experience in analysis, sales, research, or marketing Requires high proficiency with Excel. Proficient with major Microsoft Office tools. Requires strong analytical and communication skills and program/project management capabilities Highly collaborative team-player, with the ability to work effectively independently Exceptional verbal and communication skills Ability to be flexible and adaptable to changing work conditions and priorities  Nice to Have Skills & Experience Experience with Tableau and Salesforce preferred.  Job Description The professional joining our team will not only be adept at using the tools to work with the data, but they will assemble that data into high level views to communicate internally and to our external partners. Additionally, we are looking for someone that will look ahead to suggest new tools or processes for improvements in capabilities or efficiencies. We need a technical person with excellent written and verbal communication skills. This role is dynamic and has evolving needs including working with the marketing team on promotional campaigns.  Job Responsibilities Point person for enhancing customized in-house analytics tools to build reports Support departmental team with research, special projects and reports for various projects and reporting needs Assist and/or lead in the development of customer facing presentations Maintain effective working relationships with internal and external stakeholders Apply a high degree of qualitative and quantitative analytical skills in analyzing data to find key insights and develop compelling stories for stakeholders Lead or participate in special projects and other duties as directed Manage email promotional campaigns along with marketing Work with CRM system for reporting and campaign management Looking for and suggesting new tools or processes to enhance capabilities or create efficiencies",https://www.linkedin.com/jobs/view/4255246733/?eBP=NOT_ELIGIBLE_FOR_CHARGING&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=Oiwugv5D0qGKUBpMl5SDBA%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:06:16,Data Scientist,0,4255302863,Senior Data Scientist,Acumatica,"Seattle, WA",false,hace 3 horas,100,,,,,,"Acerca del empleo Company Description  Acumatica is a company on a mission. We are a leading innovator in cloud ERP with customers located around the world. But don’t take our word for it—read what analysts like G2 and Info-Tech have to say about us.  Acumatica is a leading provider of cloud business management software that empowers small and mid-size businesses to unlock their potential and drive growth. Built on the world’s best cloud and mobile technology and a unique customer-centric licensing model, Acumatica delivers a suite of fully integrated business management applications, such as Financials, Distribution, CRM, and Project Accounting, on a robust and flexible platform. In an interconnected world, Acumatica enables customers to take full control of their businesses, play to their organizations’ unique strengths, and support their clients by following them anywhere on any device.  Acumatica’s culture is casual and high-energy. We are passionate about our product and our mission, and we are loyal to each other and our company. We value work/life balance, efficiency, simplicity, freakishly friendly customer service, and making a difference in the world. Acumatica offers exceptional professional and financial growth potential.  To learn more about Acumatica’s mission, please visit: http://www.acumatica.com.  Job Description  This is an exciting opportunity for a senior data scientist to play a strategic role in shaping how data is used to drive decisions, insights, and innovation across our business, partners and customers ecosystem. In this role you will work closely with our business teams to understand their goals, challenges, and use cases – translating them into actionable data and analytics requirements.  You will help define both the analytics and data engineering dimensions of our data platform strategy. On the analytics side, you will define key business metrics, design data models, and develop insights and dashboards that inform critical tactical & strategic decisions. You will collaborate with data engineering to ensure the underlying data architecture, pipelines, and structures are aligned with analytical needs.  You will also help uncover and shape opportunities for advanced analytics and machine learning, including use case discovery, prototyping, and advising on practical deployment for our business teams. You will have the opportunity to help our business stakeholders move beyond reactive reporting to forward-looking, data-driven decision-making with scalable, value-driven advanced analytics.  Key Responsibilities  Business Partnership & Requirements Gathering Work with cross-functional business team to understand key objectives and challenges of each business function Translate business goals into data and analytical requirements for data engineering and data analytics teams Proactively identify areas where analytics and machine learning can provide enhanced value and insights beyond current scope Communicate complex findings in a clear, actionable manner to both technical & non-technical stakeholders Analytical Leadership Design, build, and implement advanced analytics models (e.g. forecasting, classification, segmentation) to support internal and customer facing use cases Serve as a thought leader on data science best practices, emerging trends, and innovation opportunities Collaboration & Enablement Work closely with data engineers to ensure data pipelines and structures align with analytical needs Help define and maintain a roadmap for analytics and ML capabilities aligned with business and product goals Mentor rising data scientists and analysts Qualifications  Education  Bachelor’s or Master’s degree in Computer Science, Data Science, or a related field  Experience  7+ years of experience in data science or advanced analytics, preferably within SaaS ERP or enterprise software Strong experience working with business and technical teams Proven ability to translate business analytics needs into well-defined & structured analytics deliverables Strong communication skills with ability to influence and educate stakeholders at all levels Experience working with large, complex datasets and modern cloud data platforms (e.g. Snowflake, Data Bricks, Big Query, AWS Spark, Dremio, Apache Iceberg) Ability to be a lead for a team of 3-5 data analysts  Technical Skills  Hands-on experience with Python or R, Advanced SQL, and machine learning libraries Strong data modeling experience Strong knowledge of ETL/ELT pipelines, streaming data, and orchestration frameworks Understanding of data governance frameworks & compliance standards Experience integrating machine learning workflows into lakehouse environments  Additional Information  Acumatica is an Affirmative Action and Equal Opportunity Employer/Veterans/Disabled. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.  If you have a disability and you believe you need a reasonable accommodation in order to search for a job opening or to submit an online application, please e-mail HR@acumatica.com. This email is created exclusively to assist disabled job seekers whose disability prevents them from being able to apply online. Only emails sent for this purpose will be returned. Emails sent for other purposes, such as following up on an application or technical issues not related to a disability, will not receive a response.  For this role, the salary range is $140,000-160,000 annually. This range represents the low and high end of the salary range for this job and may vary based on location. The actual salary offer will carefully consider a wide range of factors, including skills, qualifications, experience and other relevant elements.  At Acumatica, certain roles are eligible for additional rewards, including annual bonus and stock. These awards are allocated based on individual performance. In addition, certain roles also have the opportunity to earn sales incentives based on revenue or utilization, depending on the terms of the plan and the employee’s role.",https://www.linkedin.com/jobs/view/4255302863/?eBP=BUDGET_EXHAUSTED_JOB&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=00cjWGAyNz1HGvcbvWPMvw%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:06:34,Data Scientist,0,4255131804,Data Science & ML Engineer,TrueNorth®,Reino Unido,false,hace 10 horas,100,,,,,,"Acerca del empleo One of our clients are a leading E-commerce company are looking for an DS/ML engineer to join them for an initial 6 months contract.  Details of this contract as follows:  Location: Remote Duration: 6 months, high likelihood of extension Rate: £400 - £450 per day Status: Outside IR35 Start date: Ideally immediate (they may be able to wait up to 4 weeks for someone to start) Skills required: NLP, Modelling, Python, SQL, Databricks, Anomaly Detection Desirable: Image Classification, Airflow, Pyspark   You will be joining their customer security team, which uses machine learning to detect anomalies and erroneous activity on customer accounts. You will be building models to help detect any unwanted account takeovers by cyber criminals and build customer trust.  If this is of interest, then please apply today or send through an updated CV to:  david@truenorthgroup.io",https://www.linkedin.com/jobs/view/4255131804/?eBP=BUDGET_EXHAUSTED_JOB&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=9kVn5%2FCMk6nYCr5qzTFtPg%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:06:51,Data Scientist,0,4252676518,Senior Data Analyst: 100% remote [32334],,Estados Unidos,false,hace 8 horas,100,,,,,,"Acerca del empleo The company is a fast-growing, independently-owned real estate software firm that serves as a trusted technology partner to over 500,000 top brokerages, agents, and teams. Their branded portfolio, BoldTrail, includes BoldTrail (Front Office), BoldTrail BackOffice and BoldTrail Recruit, solutions that create a complete tech ecosystem for clients, and deliver seamless end-to-end operations to scale success at any level. With an accomplished leadership team and its talented staff, the company brings the resources, scale, and vision to deliver ongoing innovation and success to their growing customer base. We are seeking a Senior Data Analyst with expertise in product analytics, behavioral analysis, and predictive analytics to join our team. The ideal candidate will combine strong statistical knowledge with business acumen to drive product and business decisions through data-driven insights. This role is crucial in empowering teams with the data they need to make informed decisions.  Responsibilities Lead the analysis of user behavior and trends by leveraging advanced statistical methods and predictive models to generate insights into engagement and retention. Develop and standardize product metrics, aligned with company OKRs; utilizing cohort analysis to better understand user lifecycles and influence on customer lifetime value. Design and execute experimental strategies, including A/B tests to measure the impact of product changes, directly influencing product roadmap decisions. Create and maintain scalable reporting solutions that democratize access to key metrics, while ensuring data accuracy and integrity. Collaborate with cross-functional teams to define, measure, and capture data, transforming business questions into critical insights. Deliver clear, concise reports and visualizations that effectively communicate insights to both technical and non-technical audiences. Lead the analysis for customer success stories and sales enablement by creating data-backed proof points for case studies and sales narratives Mentor junior analysts while documenting and standardizing best practices for data analysis and reporting across the organization. Qualifications: Bachelor’s degree in Data Science, Statistics, Mathematics, Computer Science, or a related field (Master's degree preferred). 3-5+ years of hands-on experience with product and customer analytics with a specialty in B2B/SaaS (i.e., product usage and engagement analysis, customer lifecycle metrics)  Strong proficiency in data analysis tools such as SQL and programming languages such as Python or R, with demonstrated ability to write efficient queries and build reproducible data pipelines to support statistical and analytical models. Experience with data visualization and BI tools for creating intuitive dashboards (Tableau strongly preferred) Experience with modern data stacks including cloud-based databases (Redshift), ETL/Pipeline orchestration tools (Airflow), product analytics platforms (Segment, Amplitude) and version control/database tools (Github). Experience with experimental design and A/B testing methodologies Proven ability to lead and manage multiple initiatives from problem definition, defining success metrics, designing the experiment and communicating actionable results.  Strong understanding of data governance and data quality principles. Excellent problem-solving skills and attention to detail. Possesses strong written and verbal communication skills in order to collaborate effectively across various teams and organizational levels. Experience in the Real Estate industry is a plus.  We offer a competitive total rewards package including: Competitive salary 3 Medical plans to choose from - 1 PPO and 2 HDHPs 2 Dental plans to choose from Vision HSA - company-funded FSAs - healthcare, limited purpose, dependent care Short-Term Disability - company-paid Long-Term Disability - company-paid Basic Employee Life Insurance - company-paid Voluntary Dependent Life Insurance Voluntary Accident Insurance Voluntary Critical Illness Voluntary Hospital Indemnity Legal Plan ID Protection Pet Insurance 401(k) Retirement Savings with company match Paid PTO/Vacation/Sick Time 11 company-recognized holidays Company-paid Parental/Disability Leave   In addition, we focus on driving top results providing: Opportunities to grow within our company; Potential to work in a remote setting; Exciting/energetic work environment and fun, creative culture.",https://www.linkedin.com/jobs/view/4252676518/?eBP=NOT_ELIGIBLE_FOR_CHARGING&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=O%2B4owMQGj6nlCNkG5ANkQA%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:07:07,Data Scientist,0,4255195169,AI/ ML Engineer,Acetech Group Corporation,Estados Unidos,false,hace 5 horas,100,,,,,,"Acerca del empleo Position: AI/ ML Engineer Location:100% Remote Duration: 12+ contract   Job Description We are seeking a talented Java Full Stack Developer with expertise in AI/ML to join our dynamic team.  Responsibilities: Design, develop, and maintain scalable web applications using Java and related technologies. Implement and integrate AI/ML models and algorithms into applications, focusing on technologies such as RAG (Retrieval-Augmented Generation), MCP (Model Compression and Pruning), LlamaIndex, and LangChain. Work with vector databases to manage and query large datasets efficiently. Collaborate with cross-functional teams to define, design, and ship new features. Ensure the performance, quality, and responsiveness of applications. Identify and correct bottlenecks and fix bugs. Stay up-to-date with emerging trends and technologies in fullstack development and AI/ML.   Required Skills & Experience Bachelor's degree in Computer Science, Engineering, or a related field. Proven experience as a Fullstack Developer with a strong proficiency in Java. Hands-on experience with AI/ML technologies, including GenAI, RAG, MCP, LlamaIndex, and LangChain. Experience with vector databases and their applications. Strong understanding of front-end technologies, such as HTML, CSS, and JavaScript. Familiarity with frameworks such as Spring Boot and Hibernate.  Nice to Have Skills & Experience Master's degree in Computer Science or a related field. Experience with cloud platforms such as AWS, Azure, or Google Cloud. Knowledge of DevOps practices and tools. Contributions to open-source projects.",https://www.linkedin.com/jobs/view/4255195169/?eBP=NOT_ELIGIBLE_FOR_CHARGING&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=H7ZEsFHoC7tlDhfv5kzcBA%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:07:22,Data Scientist,0,4255203695,"Data Scientist, Entry Level",Jobright.ai,"Oregón, Estados Unidos",false,hace 6 horas,,,,,,,"Acerca del empleo At Jobright, we help high-growth startups hire top talent for their key roles.  The Voleon Group is a technology company focused on applying advanced AI and machine learning techniques to investment management. As a Data Scientist, you will be responsible for deriving insights from complex datasets, ensuring data integrity, and communicating findings to both research staff and executive leadership.  Responsibilities: Design and implement systems to ensure data correctness and monitor data health in data stores and live feeds Proactively identify abnormal production behavior and communicate them clearly to relevant stakeholders Perform extemporaneous analyses on research and production trading systems with leadership Harness financial expertise and statistical analysis to gain actionable insights into our production trading and research systems Design and implement analysis pipelines that automate those analyses found to be valuable for ongoing monitoring  Qualification:  Required: 1+ years of applied end-to-end industry experience, including internships working with complex datasets, including curation, querying, aggregation, exploratory data analysis, and visualization Experience using statistical methods to analyze data, identify patterns, conduct root cause analysis, discover insights, and recommend solutions Ability to frame and answer questions mathematically Ability to infer useful forward-looking directions from results of retrospective analysis Fluency in managing, processing, and visualizing tabular data using a combination of SQL, Pandas, and R Basic software development skills and experience with bash, linux/unix, and git Ability to refine requirements from ambiguous requests to produce reports demonstrating excellence in communication Bachelor’s degree in a quantitative discipline (statistics, biostatistics, data science, computer science, or a related field)  Preferred: Master’s degree in a quantitative discipline Prior industry experience or displayed interest in finance, such as related academic projects, coursework in financial engineering, or industry internships Experience developing in a production-facing environment and familiarity with standard concepts and tooling, e.g., CI/CD, git, Airflow",https://www.linkedin.com/jobs/view/4255203695/?eBP=BUDGET_EXHAUSTED_JOB&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=B3iXfw9iViMjCCp%2FuGWuMQ%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:07:38,Data Scientist,0,4255098146,Data Scientist,People Prime Worldwide,India,false,hace 7 horas,100,,,,,,"Acerca del empleo About Company: Client is a US-based AI infrastructure company focused on accelerating the development and deployment of AI systems. It connects companies with AI experts and provides end-to-end AI solutions, initially known for its Intelligent Talent Cloud and now offering services for designing, training, and deploying advanced AI systems. Client also focuses on advancing frontier AI model capabilities and building real-world AI applications.   Job Title: Data Scientist with Julia Experience Location: Remote Client: Turing Experience: 3+ yrs Job Type : Contract to hire. Notice Period:- Immediate joiners Only.   Note: Candidate should be comfortable to work for US Shifts/Night Shifts. Interview Mode: Virtual (Two rounds of interviews (60 min technical + 30 min technical & cultural discussion).  Roles and Responsibilities: Strong experience with Julia programming language concepts.  Industry experience and knowledge of code quality, formatting, and best practices of software development. Experience with Julia's testing ecosystem, including unit, integration, and property-based testing.  Familiarity with Julia frameworks and libraries. Knowledge of multi-threading and asynchronous programming in Julia.  Ability to work with architectural patterns and refactor code without introducing regressions. Strong debugging skills, including fixing memory and concurrency issues.  3+ years of overall work experience with 2+ years of relevant experience with Julia. Fluent in conversational and written English communication skills.",https://www.linkedin.com/jobs/view/4255098146/?eBP=BUDGET_EXHAUSTED_JOB&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=iD8v%2BNfeaX7JuLmqu%2B0VSg%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:07:54,Data Scientist,0,4255251146,Machine Learning Engineer,Creospan Inc.,Estados Unidos,false,hace 38 minutos,63,,,,,,"Acerca del empleo Job Title: ML Engineer Location: Remote Job Duration: 6 months Contract  Job Description: We are seeking skilled engineers to provide daily support for our in-house Gen AI platforms, which serve legal stakeholders. The successful candidates will be responsible for: Building and maintaining the platforms, including refactoring software as needed Troubleshooting and resolving bugs and issues that arise Collaborating with FTEs to share workload and support ongoing projects Ensuring seamless operation of the platforms to meet the needs of our legal stakeholders  Qualifications: 1) Master's/Bachelor's in Computer Science, Math, Physics, Engineering, Statistics or a related quantitative field. 2) 3+ years of experience in the design, deployment and maintenance of Machine learning pipelines and systems. 3) Demonstrable experience in applying Machine Learning algorithms to solve real-world problems 4) 3+ years of experience in design, deployment and maintenance of large data pipelines.",https://www.linkedin.com/jobs/view/4255251146/?eBP=NOT_ELIGIBLE_FOR_CHARGING&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=rZ0RLytw0x5oW2sCSdDUbQ%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:08:12,Data Scientist,0,4255319081,Data Scientist,Wiraa,Estados Unidos,false,hace 1 hora,,,,,,,"Acerca del empleo About The Company  Ulta Beauty (NASDAQ: ULTA) is the largest North American beauty retailer, offering a comprehensive range of cosmetics, skincare, haircare, fragrance, and salon services. With over 25,000 products from 500+ brands and an in-store salon in every location, Ulta is the ultimate beauty destination. Our company thrives on innovation, inclusivity, and empowering both customers and team members through the transformative power of beauty.  About The Role  As a Lead Data Scientist at Ulta Beauty, you will lead high-impact, exploratory data science initiatives at the intersection of innovation and business strategy. You will collaborate across functions to build scalable AI/ML solutions using advanced techniques spanning NLP, computer vision, and generative modeling. Reporting to senior leadership, this position is central to our innovation roadmap and will guide the development and implementation of cutting-edge solutions across the enterprise.  Responsibilities  Lead strategic data science projects aligned with Ulta’s business goals Drive innovation through experimentation, rapid prototyping, and continual learning Mentor and develop a team of data scientists, promoting best practices and technical excellence Architect, implement, and monitor scalable ML models and end-to-end pipelines Perform complex data analysis using structured and unstructured datasets Translate technical insights into clear, actionable recommendations for business partners Present findings to senior executives and stakeholders to influence key decisions Collaborate with teams across engineering, product, marketing, and finance Contribute to MLOps infrastructure and model deployment strategy Evaluate emerging technologies and provide thought leadership across AI initiatives  Qualifications  Master’s or PhD in Computer Science, Mathematics, Physics, Statistics, or a related field 5–7+ years of progressive experience in data science, machine learning, or AI roles Proficiency in Python or C++ and ML frameworks (e.g., scikit-learn, TensorFlow) Deep experience with cloud platforms such as Google Cloud, AWS, or Azure Proven track record of developing and launching ML solutions in production Solid foundation in statistics, machine learning, optimization, and software engineering Strong communication and project leadership skills with business-facing experience Ability to work in fast-paced, cross-functional environments with evolving requirements  Benefits  Competitive salary range: $119,300 – $170,000 per year Eligibility for annual performance-based bonus Paid time off, paid holidays, and wellness days Comprehensive health, dental, vision, life, and disability insurance 401(k) with company match and career development opportunities Access to Ulta Beauty's learning platform and internal mobility programs Opportunities for occasional travel (team collaboration, conferences, vendor engagement)  Equal Opportunity  Ulta Beauty is an equal opportunity employer and is committed to fostering a diverse and inclusive workplace. We consider all qualified applicants, including individuals with arrest or conviction records, in accordance with applicable laws such as the Fair Chance Ordinance in Los Angeles, San Francisco, and New York City.  Aptitudes y experiencia deseables Information Technology",https://www.linkedin.com/jobs/view/4255319081/?eBP=BUDGET_EXHAUSTED_JOB&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=k2oc7auBoGtZBPqyc%2FWN3g%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:08:29,Data Scientist,0,4255250176,Machine Learning Engineer,Intelliswift - An LTTS Company,Estados Unidos,false,hace 37 minutos,59,,,,,,"Acerca del empleo Job Title: Machine Learning Engineer (Legal GenAI Platforms) Location: Remote Duration: 6 months (possibility for extension) W2 Contract  We are looking for a highly skilled Machine Learning Engineer with 3–5+ years of hands-on experience in building and maintaining ML systems and large-scale data pipelines. This engineer will play a pivotal role in supporting internal GenAI platforms used by legal stakeholders, with a focus on reliability, scalability, and real-world ML applications.  Key Responsibilities: Develop, deploy, and maintain machine learning pipelines and data processing systems for legal tech applications. Troubleshoot platform issues, refactor software, and ensure seamless operation of GenAI platforms. Collaborate cross-functionally with engineers and data scientists to shape scalable and strategic ML solutions. Partner with legal teams to translate internal operations data into actionable insights through ML.  Qualifications: Bachelor's or Master’s in CS, Math, Engineering, Physics, Statistics, or related quantitative fields. 3+ years of experience designing, deploying, and maintaining: Machine Learning systems Data pipelines at scale Strong programming skills in Python and SQL. Demonstrated ability to apply ML algorithms to solve real-world business problems.  Nice-to-Have Skills: Experience in GenAI platform support or LegalTech ML applications. Ability to thrive in fast-paced environments and work independently. Familiarity with cloud infrastructure (e.g., AWS/GCP), ML ops tools, or model monitoring frameworks. Applied Research Scientist, Research Engineer, Machine Learning Scientist",https://www.linkedin.com/jobs/view/4255250176/?eBP=NOT_ELIGIBLE_FOR_CHARGING&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=pw1ryzbB%2BJo%2FGoexw5QzAA%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:08:47,Data Scientist,0,4252387832,Data Scientist / AI / Gen AI / Software Engineer / LLM / ML / Machine Learning / Solutions Architect,BSL Consulting,Estados Unidos,false,Publicado de nuevo hace 2 horas,100,,,,,,"Acerca del empleo Role : Data Scientist (Traditional) Type : Contract Location : Atlanta, GA (Hybrid - 3 Days a week)  Should have developed propensity models within insurance business domain  Should be proficient at Python  Should have prior experience in AWS SageMaker, Databricks, etc.  Should be familiar with NLP techniques (OCR based text extraction, document classification, document summarization)  Palantir Foundry and AIP experience is a plus   Role : Data Scientist (GenAi) Type : Contract Location : Atlanta, GA/NYC (Hybrid - 3 Days a week)  A strong AI and ML engineer with vast experience in ML, DL, NLP and Gen-AI solutions Should have insurance domain experience (specifically Underwriting/Claims) Should be proficient at Python Should have prior experience in AWS SageMaker, Databricks, etc. Should be experienced with NLP techniques (OCR based text extraction, document classification, document summarization) Should have prior experience around LLMs and Gen-AI projects Palantir Foundry and AIP experience is a plus     Role : Full Stack Software Engineer (GenAi SDLC) Type : Contract Location : Charlotte (Hybrid - 3 Days a week) Develop and deploy GenAI-powered features across the full stack (front-end, back-end, databases). Implement and manage CI/CD pipelines optimized for GenAI model deployment. Integrate GenAI models (LLMs, etc.) into existing and new software systems. Ensure data pipelines for GenAI model training and inference are efficient and reliable. Write clean, testable, and well-documented code. Troubleshoot and resolve issues across the full stack and GenAI integrations. Stay current with GenAI advancements and full-stack technologies Proficiency in multiple programming languages (e.g., Python, JavaScript, Java). Strong experience with front-end frameworks (e.g., React, Angular, Vue.js). Solid back-end development skills (e.g., Node.js, Python frameworks like Flask/Django, Spring). Experience with databases (SQL, NoSQL). Familiarity with cloud platforms (AWS). Understanding of SDLC principles and agile methodologies. Hands-on experience integrating AI/ML models into applications. Understanding of Generative AI concepts (LLMs, transformers, etc.).work with Agentic AI framework or other Gen AI models/APIs (e.g., OpenAI, Hugging Face, Google Vertex AI). Experience with containerization (Docker, Kubernetes)   Role : Solution Architect (SDLC) Type : Contract Location : Charlotte (Hybrid - 3 Days a week) Lead and manage a team of developers in a fullstack development environment. * Define the integration strategy for GenAI models (LLMs, etc.) into existing and new systems. Lead the technical vision and roadmap for GenAI solutions within the SDLC. Define data pipelines and infrastructure requirements for GenAI model training, deployment, and monitoring. Ensure alignment of GenAI solutions with business needs and technical feasibility. Collaborate with engineering, data science, and product teams to define solution requirements. Develop, enhance, and maintain applications using Python, Angular, and Java. Integrate and work with Agentic AI framework or other Gen AI models/APIs (e.g., OpenAI, Hugging Face, Google Vertex AI). Design and deploy scalable microservices-based solutions. Collaborate with Product Owners, DevOps, and QA teams in an Agile environment. Ensure code quality through peer reviews, test automation, and best practices. Contribute to architectural decisions and technical strategies.",https://www.linkedin.com/jobs/view/4252387832/?eBP=BUDGET_EXHAUSTED_JOB&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=dpucCBFI723oc7%2FiAsQOWg%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:09:03,Data Scientist,0,4255211072,Analytics Manager,Sibitalent Corp,"Nueva York, Estados Unidos",false,hace 5 horas,90,,,,,,"Acerca del empleo Role - BI/Analytics Manager  Location – Remote - Only or Self corp please   Must have leader/ manager experience SQL, Power BI, Fabric, Healthcare and Snowflake exp.",https://www.linkedin.com/jobs/view/4255211072/?eBP=NOT_ELIGIBLE_FOR_CHARGING&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=sC%2BtbpGhjXakuPKxoonMDw%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:09:18,Data Scientist,0,4255214202,Senior Data Engineer,Harnham,"Inglaterra, Reino Unido",false,hace 4 horas,40,,,,,,"Acerca del empleo DATA ENGINEER - DBT / AIRFLOW / DATABRICKS  4-MONTH CONTRACT   £450-550 PER DAY OUTSIDE IR35 This is an exciting opportunity for a Data Engineer to join a leading media organisation working at the forefront of data innovation. You'll play a key role in designing and building the data infrastructure that supports cutting-edge machine learning and LLM initiatives. Expect to work closely with data scientists, helping to power intelligent content and audience tools across the business. THE COMPANY  A major player in the media sector, this company is investing heavily in its data capabilities to support everything from real-time analytics to AI-powered content discovery. The environment is collaborative, fast-moving, and focused on innovation. With strong engineering foundations already in place, they're looking for a contractor to accelerate delivery of critical pipelines and platform improvements. THE ROLE  You'll join a skilled data team to lead the build and optimisation of scalable pipelines using DBT, Airflow, and Databricks. Working alongside data scientists and ML engineers, you'll support everything from raw ingestion to curated layers powering LLMs and advanced analytics.  Your responsibilities will include: Building and maintaining production-grade ETL/ELT workflows with DBT and Airflow Collaborating with AI/ML teams to support data readiness for experimentation and inference Writing clean, modular SQL and Python code for use in Databricks Contributing to architectural decisions around pipeline scalability and performance Supporting the integration of diverse data sources into the platform Ensuring data quality, observability, and cost-efficiency KEY SKILLS AND REQUIREMENTS Strong experience with DBT, Airflow, and Databricks Advanced SQL and solid Python scripting skills Solid understanding of modern data engineering best practices Ability to work independently and communicate with technical and non-technical stakeholders Experience in fast-paced, data-driven environments DESIRABLE SKILLS Exposure to LLM workflows or vector databases Experience in the media, content, or publishing industries Familiarity with cloud data platforms (e.g., AWS or Azure) Knowledge of MLOps and ML/data science pipelines HOW TO APPLY  To register your interest, please apply via the link or get in touch with your CV.",https://www.linkedin.com/jobs/view/4255214202/?eBP=NOT_ELIGIBLE_FOR_CHARGING&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=ripjPcEZ7ZvEvpvZ8ub2Ww%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:09:35,Data Scientist,0,4255246753,Artificial Intelligence Engineer,Avance Consulting,Estados Unidos,false,hace 51 minutos,37,,,,,,"Acerca del empleo Role: AI/ML Engineer Location : Dallas /Jersey city /New york city(remote) Full time  Who are we looking For: We are seeking a skilled and motivated AI/ML Engineer with 10–15 years of hands-on experience in building and deploying scalable machine learning solutions. The ideal candidate will have a deep understanding of the end-to-end ML lifecycle, MLOps practices, and cloud-native technologies. You will play a critical role in automating, scaling, and optimizing our clients’ machine learning systems, and contribute to advancing MLOps maturity across the organization.  Key Responsibilities: Automate the deployment, monitoring, and retraining machine learning models across various environments. Design, develop, and deploy scalable ML tools and services for training and inference tailored to client needs. Identify and evaluate emerging technologies to enhance the performance, scalability, and reliability of ML systems. Drive continuous improvement of MLOps pipelines, ensuring alignment with industry best practices. Troubleshoot issues throughout the ML lifecycle—from data preprocessing to model serving—within MLOps frameworks. Implement monitoring and detection mechanisms for data drift and model drift. Contribute to internal research initiatives and best practice frameworks to elevate organizational MLOps maturity. Prepare documentation and deliver presentations on MLOps tools, processes, and enhancements. Technical Skills – Must Have Bachelor’s or master’s degree in computer science, Data Science, or a related field. Strong programming skills in Python with hands-on experience in ML frameworks such as TensorFlow, PyTorch, and scikit-learn. Experience with ML workflow orchestration tools like MLflow or Kubeflow. Solid understanding of data architecture, data engineering, and data management practices.",https://www.linkedin.com/jobs/view/4255246753/?eBP=BUDGET_EXHAUSTED_JOB&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=i9jM%2BPI6vMm0q0e1h5l2yw%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:09:52,Data Scientist,0,4252652803,Associate Data Scientist,Why Hiring,Canadá,false,hace 13 horas,100,,,,,,"Acerca del empleo At Why Hiring, we believe in the power of connecting talented individuals with incredible remote job opportunities. Our mission is to simplify the job search process and empower professionals to find fulfilling roles that align with their skills and passions, regardless of geographical constraints.   In this role, you will collaborate with top-tier professionals in a setting that nurtures both creativity and career development. Engaging with multimodal datasets, you'll be instrumental in developing pioneering solutions on an extended roadmap.  Responsibilities:  Utilize cutting-edge algorithms and libraries to address complex client challenges. Design and deploy advanced AI features. Analyze extensive multi-modal datasets to derive insights and features for downstream models and applications. Develop and refine traditional machine learning models for both supervised and unsupervised learning, as well as advanced AI models for tasks including image-to-text, text-to-image, question-answering, and summarization. Keep up-to-date with the latest advancements in AI research and integrate these into our products and services. Effectively communicate technical challenges and solutions to both technical and non-technical stakeholders and team members.  Qualifications: Proficiency in Python programming. Knowledge of agile software development practices, including code reviews, unit testing, and version control with git. Practical experience with libraries and frameworks such as Hugging Face, NLTK, SpaCy, TensorFlow, PyTorch, and Scikit-Learn. Strong grasp of deep learning architectures, including transformers, recurrent and convolutional neural networks, and attention mechanisms.",https://www.linkedin.com/jobs/view/4252652803/?eBP=BUDGET_EXHAUSTED_JOB&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=x%2FLNg%2FYFROA%2BbXHTKxlBSA%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:10:08,Data Scientist,0,4255067480,Senior Data Analyst,OGC Global,Washington DC-Baltimore y alrededores,false,hace 9 horas,,,,,,,"Acerca del empleo OGC is a boutique research and consulting agency specializing in data-driven strategy, quantitative analytics, and Customer Experience (CX) program design and optimization. We work with some of the world’s largest organizations across various industries, including Healthcare, Financial Services, Specialty Retail, and Telecommunications, helping them gain a deep understanding of their customers, develop actionable insights, and improve business processes.  We are looking for a Senior Data Analyst to join our team and support one of our key clients. In this role, you will contribute to the rollout and optimization of CX programs by delivering meaningful insights and analysis that help drive customer satisfaction and business performance.  About the role You will serve as a dedicated expert embedded within the Customer Experience team at Salesforce. In this client-facing role, you’ll work closely with business unit leaders across the organization to support data-driven decision-making and the ongoing enhancement of CX programs. Your responsibilities will include querying, refining, and synthesizing customer and operational data from various internal systems to uncover actionable insights. You will also contribute to the evolution of CX processes across the Salesforce ecosystem, helping to ensure that the voice of the customer is integrated into strategic priorities. This is a full-time, remote position.  Responsibilities: Manage and support global Customer Experience (CX) programs in collaboration with cross-functional teams. Oversee project timelines, ensuring smooth coordination across internal teams and external stakeholders. Manage relationships with implementation vendors, tracking deliverables and performance. Provide analytical support using tools like Excel, Python, and SQL to turn data into actionable business insights. Design, test, and refine customer surveys based on client objectives and CX strategy. Develop clear, executive-ready reports and dashboards using data from multiple sources. Troubleshoot technical and operational challenges, manage vendor relationships, and optimize CX reporting platforms. Communicate project updates, insights, and recommendations clearly to internal managers and client teams.  Requirements: Bachelor’s degree in Business, Social Sciences, Statistics, Computer Science, or a related field. 3-5 years of experience in customer experience, market research, business analysis, or consulting. Strong proficiency with Excel, Python, SQL, and data visualization tools (e.g., Tableau, Power BI). Experience working with CX platforms such as Medallia or Qualtrics is a significant advantage. Experience building executive level reporting decks. Familiarity with statistical tools (e.g., Stata, SPSS, R) and basic programming knowledge (e.g., XML, VBA) is a plus. Fast learner with a demonstrated ability to adopt new tools and methodologies quickly. Excellent attention to detail, with strong written and verbal communication skills. Experience in survey design, sampling strategies, and analyzing survey data is a plus. Strong time management skills; able to balance multiple projects simultaneously. Collaborative, self-motivated, and comfortable working both independently and within a team.",https://www.linkedin.com/jobs/view/4255067480/?eBP=BUDGET_EXHAUSTED_JOB&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=zngtkFyRW%2BkRm0uYHEkWgQ%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:10:27,Data Scientist,0,4255347705,ML Ops Engineer,IQRush.ai,Estados Unidos,false,hace 36 minutos,18,,,,,,"Acerca del empleo About IQRush.ai IQRush.ai is a generative search optimization platform that empowers brands and agencies to maximize their visibility in AI-driven search engines. We blend predictive analytics, LLM emulation, and real-time data insights to help marketers understand how LLMs select and surface content—driving more qualified traffic, engagement, and revenue.  Role Overview We’re seeking a seasoned ML Ops Engineer to design, build, and operate the end-to-end infrastructure that powers our large-scale ML/AI services. You’ll partner closely with data scientists, software engineers, and DevOps teams to productionize models, automate data pipelines, and ensure rock-solid reliability, performance, and security of our ML systems.  Key Responsibilities · Azure Cloud Infrastructure:  (3+ yrs) Design and provision Azure resources (AKS, Function Apps, Blob Storage, SQL Database, Cosmos DB) with Terraform or ARM templates, including networking, security groups, and Azure AD/Managed Identities.  · Data & Feature Pipelines:  (2+ yrs) Develop ETL/ELT workflows using Azure Data Factory, Airflow, Prefect or similar; implement batch/streaming ingestion (Event Hubs, Kafka) and manage a feature store (Feast) and vector DB (Weaviate).  · Model Training & Versioning:  (2+ yrs) Collaborate on training pipelines with Python (PyTorch, TensorFlow, scikit-learn), track experiments and artifacts (MLflow, DVC, Azure ML), and implement knowledge distillation workflows.  · CI/CD & Deployment:  (3+ yrs) Build CI/CD pipelines (GitHub Actions, Azure DevOps, Jenkins) covering tests, container builds, model validation guardrails, and canary/blue-green Kubernetes deployments; containerize with Docker and manage Helm charts for AKS.  · Monitoring & Observability: Mid-Senior (2+ yrs) Instrument metrics (Prometheus/Grafana, Azure Monitor), centralize logs (Azure Log Analytics, ELK), set up alerting for drift, latency, and errors, and maintain dashboards and runbooks.  · Integrations & API Gateways: Mid-Senior (2+ yrs)) Design and maintain RESTful APIs (FastAPI, Flask, Azure API Management) and integrate third-party connectors (Zapier) for flexible data ingestion and delivery.  · Security & Governance: Mid-Senior (3+ yrs) Enforce least-privilege (Azure RBAC), implement secrets management (Key Vault), scan container images, and document data lineage and compliance standards.  · Collaboration & Documentation: Mentor junior engineers, write runbooks, architecture diagrams, and best-practice guides, and participate in agile ceremonies.   Required Qualifications · 3+ years of MLOps or DevOps+ML production experience  · Programming & DevOps: o Expert Python; familiarity with Go, Java, or Scala a plus o Docker, Kubernetes (AKS) and Terraform/ARM for infrastructure as code  · Cloud Services: o Azure: AKS, Function Apps, Blob Storage, SQL Database, Cosmos DB o CI/CD: GitHub Actions, Azure DevOps  · Core ML/AI Concepts: o Algorithms & Modeling: classification, regression, clustering, recommendation systems, neural networks (CNNs, RNN Transformers), tree-based methods (XGBoost, LightGBM) o Evaluation Metrics: accuracy, precision/recall, ROC-AUC, F1, log loss, mean squared error, aligned to business objectives  · Frameworks & Libraries: o Deep Learning: TensorFlow 2.x, PyTorch, Keras (model building, training, export SavedModel/TorchScript) o Classical ML: scikit-learn, XGBoost, LightGBM o Versioning & Tracking: MLflow, DVC, Azure ML for experiments, hyperparameters, and artifact management  · Feature Engineering & Data Preprocessing: o In-Memory: Pandas, NumPy o Distributed: Spark (PySpark/Scala) o Feature Stores: Feast, Tecton, ensuring consistency between training and serving  · Monitoring & Observability: o Metrics: Prometheus, Grafana, Azure Monitor o Logging: Azure Log Analytics, ELK  · Security & Governance: o Azure RBAC, Key Vault secrets management, image scanning, compliance documentation   Preferred Skills Experience with vector databases (Weaviate, Pinecone) and semantic search Knowledge distillation, model compression, and LLM optimization Real‑time streaming platforms (Azure Event Hubs, Kafka) Familiarity with API gateway solutions (Azure API Management, Exposure to AutoML / hyperparameter tuning tools (Optuna, Azure ML AutoML)  Why Join Us AI Innovation: Build the backbone of a platform powering AI‑driven search optimization. Tech Stack: Work with LLMs, vector databases, serverless compute, and modern DevOps practices. Collaborative Culture: Thrive in a small startup with a cross‑functional team where your contributions shape product direction. Professional Growth: Access to training budgets, conferences, and experimentation time. Benefits: Great health and dental benefits, and other compensation  To Apply: Send your resume and a summary of an end‑to‑end ML Ops project you led to tracie@iqrush.ai. We look forward to defining the future of AI infrastructure together!",https://www.linkedin.com/jobs/view/4255347705/?eBP=NOT_ELIGIBLE_FOR_CHARGING&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=%2ByDjZpa%2FqzeiLJUGn%2BB%2FfQ%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:10:44,Data Scientist,0,4251730580,Data Scientist,NMV Innovation Services,Bulgaria,false,Publicado de nuevo hace 7 horas,52,,,,,,"Acerca del empleo We are looking for a Senior Data Scientist(s) to join a global analytics initiative focused on delivering large-scale machine learning models within a complex financial services environment.  Key Responsibilities: Design, implement, and optimize machine learning models for clustering, classification, and risk-based segmentation Process and analyze complex transactional datasets, enhancing model performance and scalability Conduct advanced statistical modeling, scenario tuning, and parameterization activities Work extensively with Apache Spark (including internals), Python, and Git to develop, test, and operationalize solutions Collaborate closely with data engineering and business teams to ensure smooth integration and continuous model refinement Requirements Master's degree in Data Science or a related discipline 7+ years of hands-on experience in ML/AI model development following completion of the master's degree Deep understanding of clustering and classification algorithms Experience working with structured transactional or behavioral data Proficiency with Apache Spark (including internals), Python, and Git Strong communication skills in English (written and verbal) Experience in financial services, banking, or large-scale transactional environments is a plus",https://www.linkedin.com/jobs/view/4251730580/?eBP=BUDGET_EXHAUSTED_JOB&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=DNC8Z%2FWmXeiv%2BzMyMTxx2w%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:11:02,Data Scientist,0,4255182864,Data Visualization Lead,Software Technology Inc.,"Pennsylvania, Estados Unidos",false,hace 6 horas,73,,,,,,"Acerca del empleo Must have Skills: Skill 1 – 7Yrs of Exp – Deck.gl, React, Skill 2 – 7Yrs of Exp – JavaScript, HTML/CSS, Skill 3 – 5Yrs of Exp – SQL  Good To have Skills: Skill 1 – 3 Yrs of Exp – Carto, Skill 2 – 3 Yrs of Exp – JSON, Skill 3 – 3 Yrs of Exp – API, Skill 4 – 3 Yrs of Exp - CI/CD, Java   Domain- Telecom is More Plus  Over View of the job: Mandatory Skills: Deck.gl, React, JavaScript, HTML/CSS, SQL Optional Skills: Carto, JSON, API, CI/CD, Java   Job Description:- We are seeking an experienced Data Visualization Lead to design and build advanced, interactive visualizations that translate complex datasets into compelling insights. This role demands a deep understanding of React and Deck.gl, along with strong UI/UX sensibilities and a collaborative, leadership-oriented mindset. You'll lead a small team of developers and work closely with data scientists, engineers, and product managers to shape data-driven user experiences.  Key Responsibilities:- Design, architect, and develop high-performance, interactive data visualizations using React, Deck.gl, and supporting technologies Lead a team of visualization engineers, providing technical guidance, code reviews, and mentorship. Collaborate with cross-functional teams to gather requirements and translate them into effective visual storytelling. Optimize rendering performance for large-scale geospatial and temporal datasets. Ensure visualizations are accessible, intuitive, and responsive across devices. Maintain a scalable visualization codebase, implementing best practices in testing, performance, and maintainability. Stay current on trends in data visualization and front-end technologies to guide the team's innovation.  Required Qualifications:- 8+ years of experience in front-end development, with at least 2 years focused on data visualization. Proficiency in React.js and Deck.gl (including Layers, Views, and integration with Carto). Strong understanding of JavaScript (ES6+), HTML/CSS, and rendering pipelines (WebGL, Canvas). Experience with data manipulation libraries (e.g., D3.js, Lodash) and working with APIs or large datasets. Familiarity with geospatial data formats (GeoJSON, TopoJSON, tilesets) and coordinate systems. Experience leading engineering projects or small teams. Excellent communication and visual storytelling skills.  Preferred Qualifications:- • Experience with design systems, Figma or Storybook. • Background in geographic information systems (GIS) or urban data. • Familiarity with state management (e.g., Redux, Zustand) and build tools (Vite, Webpack). • Knowledge of performance profiling and optimization tools. • Prior experience in fast-paced agile environment.",https://www.linkedin.com/jobs/view/4255182864/?eBP=NOT_ELIGIBLE_FOR_CHARGING&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=GVy3yLZ43kKI65ylvXLQMA%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:11:20,Data Scientist,0,4255194624,Data Scientist,micro1,Brasil,false,hace 4 horas,,,,,,,"Acerca del empleo Job Title: Data Scientist  Job Type: Full-time, Contractor  Location: Remote  About Us: Our mission at micro1 is to match the most talented people in the world with their dream jobs. If you are looking to be at the forefront of AI innovation and work with some of the fastest-growing companies in Silicon Valley, we invite you to apply for a role. By joining the micro1 community, your resume will become visible to top industry leaders, unlocking access to the best career opportunities on the market.  Job Summary: Join our customer’s team as an Data Scientist and work at the forefront of machine learning and generative AI. You will design, build, and deploy innovative AI solutions that leverage state-of-the-art technologies such as LLMs and advanced NLP, while collaborating closely with cross-functional teams. This is a unique opportunity to deliver impactful solutions on massive datasets within a high-caliber, remote-first environment.  Key Responsibilities: Build, refine, and use advanced ML engineering platforms and reusable components to deliver scalable AI solutions. Implement ML Ops processes, tracking model KPIs, monitoring drift, and establishing robust feedback loops for continuous improvement. Deploy and operationalize deep learning models, focusing on LLMs and generative AI, ensuring reliability and performance at scale. Design and orchestrate model pipelines including feature engineering, inferencing, and continuous training to meet strict SLAs. Collaborate with client-facing teams to understand high-level business context and translate it into technical requirements. Write production-ready code with a focus on testability, maintainability, and handling edge cases and errors gracefully. Participate actively in agile ceremonies, communicate progress effectively, and adhere to best practices for architecture, design, and code quality.  Required Skills and Qualifications: Bachelor’s or Master’s degree in Computer Science or a related field from a top-tier university. 4+ years of hands-on experience in machine learning, deep learning, and fine-tuning models (LLMs). Expert-level proficiency in Python; experience with backend API design and vector databases. Solid understanding of ML Ops, including measuring and tracking model performance, and MLFlow. Demonstrated experience in NLP, generative AI, and deploying real-time model predictions. Strong communication skills—both written and verbal—are essential for cross-functional collaboration. Experience with ML frameworks such as Keras and HuggingFace.  Preferred Qualifications: Familiarity with DevOps practices, CI/CD pipelines, cloud architecture, and data security. Experience in data engineering for big data systems and knowledge of PySpark or Scala. Background in computer vision and implementing end-to-end feature engineering pipelines.",https://www.linkedin.com/jobs/view/4255194624/?eBP=NOT_ELIGIBLE_FOR_CHARGING&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=nFWei%2FLH5GOIqNBY8HT7KQ%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:11:35,Data Scientist,0,4255300403,Data Visualization Lead,SP Software Solutions,Estados Unidos,false,hace 4 horas,38,,,,,,"Acerca del empleo Role: Data Visualization Lead Location: Philadelphia, PA or Remote Duration: Long term Location Philadelphia, PA or remote in the US Mandatory Skills: Deck.gl, React, JavaScript, HTML/CSS, SQL Optional Skills: Carto, JSON, API, CI/CD, Java  Job Description  We are seeking an experienced Data Visualization Lead to design and build advanced, interactive visualizations that translate complex datasets into compelling insights. This role demands a deep understanding of React and Deck.gl, along with strong UI/UX sensibilities and a collaborative, leadership-oriented mindset. You'll lead a small team of developers and work closely with data scientists, engineers, and product managers to shape data-driven user experiences. ________________________________________ Key Responsibilities • Design, architect, and develop high-performance, interactive data visualizations using React, Deck.gl, and supporting technologies • Lead a team of visualization engineers, providing technical guidance, code reviews, and mentorship. • Collaborate with cross-functional teams to gather requirements and translate them into effective visual storytelling. • Optimize rendering performance for large-scale geospatial and temporal datasets. • Ensure visualizations are accessible, intuitive, and responsive across devices. • Maintain a scalable visualization codebase, implementing best practices in testing, performance, and maintainability. • Stay current on trends in data visualization and front-end technologies to guide the team's innovation. ________________________________________ Required Qualifications • 8+ years of experience in front-end development, with at least 2 years focused on data visualization. • Proficiency in React.js and Deck.gl (including Layers, Views, and integration with Carto). • Strong understanding of JavaScript (ES6+), HTML/CSS, and rendering pipelines (WebGL, Canvas). • Experience with data manipulation libraries (e.g., D3.js, Lodash) and working with APIs or large datasets. • Familiarity with geospatial data formats (GeoJSON, TopoJSON, tilesets) and coordinate systems. • Experience leading engineering projects or small teams. • Excellent communication and visual storytelling skills. ________________________________________ Preferred Qualifications • Experience with design systems, Figma or Storybook. • Background in geographic information systems (GIS) or urban data. • Familiarity with state management (e.g., Redux, Zustand) and build tools (Vite, Webpack). • Knowledge of performance profiling and optimization tools. • Prior experience in fast-paced agile environment.",https://www.linkedin.com/jobs/view/4255300403/?eBP=NOT_ELIGIBLE_FOR_CHARGING&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=%2BOMJuYAkRTmRC8%2Bdiq%2Bj7A%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:11:50,Data Scientist,0,4255215296,Data Scientist Intern (AI-First),Belozfi (YC W22),"Ciudad de México, México",false,hace 4 horas,100,,,,,,"Acerca del empleo Belozfi isn’t your average fintech. We’re rewriting how credit works for millions of underbanked Mexicans — combining micro-loans with AI-native product thinking. YC-backed, relentlessly curious, and allergic to boring. We're assembling a lean, sharp, AI-first Growth Team — and we're looking for a Data Scientist Intern who can do way more than clean data. We want a builder, a hacker, a metrics whisperer. If you've ever dreamt of shipping AI-powered agents, breaking stuff (with care), and learning from real impact at scale — this one's for you.  🧠 What You’ll Actually Do Build AI Agents & Automations: Using tools like n8n, Relevance AI, and others to create internal Model Context Protocols (MCPs) — basically mini-AI workflows that power real product features. Run Experiments Like a Bold Scientist: Rapid A/B tests, usage analyses, activation flows — all powered by data and your intuition. Map Growth Magic: Model attribution across performance channels and find unfair advantages. Turn KPIs Into Fireworks: Set up real-time alerts, dashboards, and signals that keep the whole team sharp. Propose Wild Ideas. Then Build Them: We mean it. You won’t just analyze — you’ll prototype MVPs (with our eng team) to test business hypotheses. Fast.  🧰 Tools of the Trade Languages: Python, SQL Stacks: n8n, Relevance AI, OpenAI APIs, Vector DBs Ops: Slack, Metabase, Linear, Postman — and anything you bring to the table  🎓 Who You Are An undergrad (Data Science, Engineering, or related) — or just obsessed with AI. Fluent in Python, SQL, and logic. Interested in product experimentation and how things actually grow. You prefer breaking and building over endless planning. You can operate remotely, independently, and with urgency. Bonus: You speak English well enough to argue with ChatGPT.  💸 What’s In It for You? Paid Internship: 6,000–10,000 MXN net/month Flexible timeline: We move fast. You will too. Path to the AI Crack Team: Our elite full-time squad of builders. High-stakes learning: You’ll be on the front lines of AI-native product growth.  🌱 Why Belozfi? We’re not hiring a data janitor. We’re hiring a Data Operator. Someone who wants to build real things using AI, not just analyze outcomes. You’ll leave this internship thinking like a product founder — only faster, sharper, and more AI-native. If that excites you, let’s build together.  📩 Apply now: alejandro@amiloz.com",https://www.linkedin.com/jobs/view/4255215296/?eBP=BUDGET_EXHAUSTED_JOB&refId=wQaw08oQCrtzxCAzCZZWHg%3D%3D&trackingId=d%2BVgfSD9PEZDfCGAU%2BGF%2Fg%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:12:56,Data Engineer,0,4245379037,Data Engineer,Jack,Estados Unidos,false,Publicado de nuevo hace 7 horas,,,,,,,"Acerca del empleo Jack is helping a leading kidney care management organization find a skilled Data Engineer to support their mission to reimagine healthcare. This company partners closely with physicians to improve the lives of patients through advanced data systems and compassionate innovation. As a Data Engineer, you'll play a critical role in building and optimizing data pipelines, supporting cloud migration efforts, and contributing to the overall architecture of a modern, scalable data ecosystem. This is an opportunity to join a fast-growing, mission-driven team focused on transforming how healthcare data is leveraged to improve outcomes. You'll collaborate cross-functionally, innovate constantly, and directly impact systems that support patients nationwide.  Responsibilities Collaborate with development teams to ensure timely and successful project delivery. Design, review, and deploy SQL code, while assisting with schema design and query optimization. Monitor, maintain, and troubleshoot data pipelines to resolve bottlenecks and ensure performance. Provide mentorship to junior engineers and guide best practices in development methodologies and frameworks. Contribute to the design and development of solutions within the existing Datawarehouse and Lakehouse architecture. Ensure proper documentation and knowledge sharing within the team to support smooth project hand-offs and scalability. Participate in defining methodologies and building tools within the Lakehouse and Datawarehouse infrastructure. Research and propose new technologies and enhancements for ongoing process improvement. Support cloud migration initiatives and the integration of data systems with external applications.  Requirements:  Education & Experience: Bachelor’s degree with 3–5 years of experience in data engineering, or Master’s degree with 3+ years of experience. Technical Expertise: Strong command of Azure-based tools including Azure Data Factory, Azure SQL databases, and Databricks. Deep experience with the Microsoft SQL Server stack (SSIS, ADF). Proficient in Python for data manipulation and pipeline support. Architecture & Integration: Understanding of data lake and Lakehouse principles, data modeling, and data warehousing best practices. Experience with cloud migration projects and integrating with third-party applications. Communication & Collaboration: Excellent verbal and written communication skills. Strong presentation skills for stakeholder meetings, requirement gathering, and feedback sessions. Work Ethic: Proven ability to meet tight deadlines without sacrificing quality. Self-driven and collaborative, with a continuous improvement mindset.   Benefits Meaningful Work: Contribute to improving the lives of patients through advanced data solutions in the healthcare space. Growth-Oriented Culture: Collaborate with experienced professionals and receive mentorship opportunities. Modern Tech Stack: Work hands-on with tools like Azure Data Factory, Databricks, SQL Server, and Python in a cloud-native environment. Innovation-First Environment: Drive improvements and suggest enhancements that shape the future of the company’s data infrastructure. Remote Flexibility: Work remotely while contributing to projects that make a real-world impact.",https://www.linkedin.com/jobs/view/4245379037/?eBP=BUDGET_EXHAUSTED_JOB&refId=Y1wis0lI87BUn09unY02kg%3D%3D&trackingId=GME8qIoMJ2t%2FOnZNeAUYpA%3D%3D&trk=flagship3_search_srp_jobs
23Jun2025-16:13:13,Data Engineer,0,4255129998,Data Engineer,Infoplus Technologies UK Limited,"París, Isla de Francia, Francia",false,hace 10 horas,92,,,,,,"Acerca del empleo The Data Engineer designs and maintains scalable data pipelines and infrastructure for real-time analytics, ensuring data quality and security. The Data Engineer will collaborate with cross-functional teams, optimize performance, and innovate through automation.  Roles and Responsibilities: Build and Optimize Data Pipelines: Analyze and organize raw data from various internal and external sources. Design, develop, and manage scalable, high-performance and resilient data pipelines that process, transform, and make data accessible for real-time analytics and reporting. Data Infrastructure Development: Design, build, and maintain data infrastructure to ensure data is reliable, accessible, and secure for various applications and stakeholders. Implement lake-house architecture. Data Integration: Analyze business use case, perform data profiling and implement data transformations required for curating raw data into AI/ML and BI ready data. Streaming & Batch Processing: Build streaming and batch data pipelines that are reusable, fault-tolerant and scalable. Data Quality & Governance: Implement data integrity validations and data quality checks for ensuring accuracy, consistency, and completeness across all datasets. Collaboration & Cross-Functional Partnerships: Collaborate with platform engineers, data analysts, platform engineers and business stakeholders to define and implement data requirements and deliver end-to-end solutions. Data Warehouse Design: Design, implement, and optimize data lake, data warehouse and data mart to meet analytics and reporting needs.  Innovation & Automation: Identify opportunities to automate data workflows, streamline processes, and introduce best-in-class tools and frameworks that enhance productivity and efficiency. Performance Tuning: Continuously monitor and tune data pipelines and infrastructure for optimal performance, scalability, and cost-efficiency.  Required Skills: Experience: 5 to 10 years of experience building and maintaining enterprise-level data applications on distributed systems at scale. Programming Skills: Expert proficiency in SQL, Python or similar language for data processing and automation. Experience building semantic processes for distributed data applications. Data Pipeline: Experience in building scalable and resilient ELT data pipelines using modern ELT tools like DBT, Azure, Airflow, Fivetran or similar. Knowledge of streaming platforms like Kafka, Spark or similar. Data Lake & Warehouse: Experience with cloud-based data platforms like Snowflake. Advanced proficiency with SQL, writing complex queries and optimizing performance. Familiar with dimensional and party data models. Data Governance: Knowledge of data governance practices, including RBAC, RLS, data masking, data lineage and compliance with regulatory standards (e.g., GDPR, HIPAA). Experience with data governance tools such as Datahub or Collibra. Automation & DevOps: Expertise in CI/CD pipelines with tools such as GitHub Actions, Jenkins, or AWS CodePipeline and containerization (Docker, Kubernetes) to automate and manage data infrastructure. Experience in implementing observability using tools such as Prometheus, Grafana, and AWS CloudWatch. Automated testing frameworks (e.g., JUnit, PyTest).",https://www.linkedin.com/jobs/view/4255129998/?eBP=BUDGET_EXHAUSTED_JOB&refId=Y1wis0lI87BUn09unY02kg%3D%3D&trackingId=7KpZ4lCxf%2BAK4WSAhH92XA%3D%3D&trk=flagship3_search_srp_jobs
